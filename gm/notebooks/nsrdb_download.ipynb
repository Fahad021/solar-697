{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890cbdbe-592b-4bc6-83d0-eadf13e42c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f75a151-807b-4ccc-a7f1-9f735317e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "import sqlite3\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "import logzero\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from logzero import logger\n",
    "from tqdm import tqdm\n",
    "from yaml import dump, load, safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7ea666-17e0-4f2e-8c27-85f599650937",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"logs/\"\n",
    "log_file = \"nsrdb_test.log\"\n",
    "\n",
    "logzero.logfile(log_path + log_file, maxBytes=1e6, backupCount=5, disableStderrLogger=True)\n",
    "logger.info(f\"{log_path}, {log_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ebae6f-c7d2-4aab-9b92-2ba92352e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"../source\")\n",
    "sys.path.append(\"../../sql\")\n",
    "import queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54798d9e-ad6f-48a0-ae8f-fb98a9ecd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = None\n",
    "try:\n",
    "    with open(\"../source/config.yml\", \"r\") as config_in:\n",
    "        configs = load(config_in, Loader=yaml.SafeLoader)\n",
    "        logger.info(f\"{configs}\\n\")\n",
    "except:\n",
    "    logger.error(f\"config file open failure.\")\n",
    "    exit(1)\n",
    "\n",
    "cfg_vars = configs[\"url_variables\"]\n",
    "logger.info(f\"variables: {cfg_vars}\\n\")\n",
    "\n",
    "years = configs[\"request_years\"]\n",
    "logger.info(f\"years: {years}\\n\")\n",
    "\n",
    "db_path = configs[\"file_locations\"][\"db_path\"]\n",
    "city = configs[\"location_info\"][\"city\"]\n",
    "state= configs[\"location_info\"][\"state\"]\n",
    "db_file = city + \"-\" + state + \".db\"\n",
    "db_table1 = configs[\"file_locations\"][\"db_table1\"]\n",
    "db_table2 = configs[\"file_locations\"][\"db_table2\"]\n",
    "\n",
    "logger.info(f\"{db_path}, {db_file}\")\n",
    "\n",
    "nrows = configs[\"num_rows\"][0]\n",
    "logger.info(f\"number of rows: {nrows}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4a9a7d4-d2c7-4c33-9a79-1e6ab72a8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"../source/zipcodes_\" + city + \"-\" + state + \".yml\", \"r\") as locs_in:\n",
    "        locs = load(locs_in, Loader=yaml.SafeLoader)\n",
    "        logger.info(locs)\n",
    "except:\n",
    "    logger.error(f\"location file open failure.\")\n",
    "    exit(1)\n",
    "\n",
    "zip_codes = locs[\"zipcodes\"]\n",
    "\n",
    "logger.info(f\"zip codes: {zip_codes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc8ed59-8f8b-4a9a-9cda-fa686c27c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish db connection and cursor\n",
    "conn = sqlite3.connect(db_path + db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(queries.create_table_geo_zipcodes)\n",
    "conn.commit()\n",
    "cursor.execute(queries.create_table_nsrdb)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073ff8a-44f7-433b-bf35-48cd1c645358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm(years):\n",
    "    for zip_code in zip_codes.keys():\n",
    "        req_str = (\n",
    "            f\"https://developer.nrel.gov/api/solar/nsrdb_psm3_download.csv?\"\n",
    "            + f'wkt=POINT({zip_codes[zip_code][\"lon\"]}%20{zip_codes[zip_code][\"lat\"]})'\n",
    "            + f\"&names={year}\"\n",
    "            + f'&leap_day={cfg_vars[\"leap_year\"]}'\n",
    "            + f'&interval={cfg_vars[\"interval\"]}'\n",
    "            + f'&utc={cfg_vars[\"utc\"]}'\n",
    "            + f'&full_name={cfg_vars[\"name\"]}'\n",
    "            + f'&email={cfg_vars[\"email\"]}'\n",
    "            + f'&affiliation={cfg_vars[\"affiliation\"]}'\n",
    "            + f'&mailing_list={cfg_vars[\"mailing_list\"]}'\n",
    "            + f'&reason={cfg_vars[\"use\"]}'\n",
    "            + f'&api_key={cfg_vars[\"key\"]}'\n",
    "            + f'&attributes={cfg_vars[\"attrs\"]}'\n",
    "        )\n",
    "\n",
    "        logger.info(f\"{req_str}\\n\")\n",
    "\n",
    "        # sleep so we don't overrun the rate NREL limit\n",
    "        sleep(2)\n",
    "        try:\n",
    "            df_raw = pd.read_csv(req_str, nrows=nrows)\n",
    "            logger.info(\"reg_str successful.\")\n",
    "        except:\n",
    "            logger.error(f\"Error requesting\\n{req_str}\\n\")\n",
    "\n",
    "        # query and extract the first 2 lines to get metadata:\n",
    "        df_meta = df_raw.iloc[0].copy()\n",
    "        # display(df_meta)\n",
    "\n",
    "        row1_cols = df_raw.iloc[1]\n",
    "        new_header = [item.replace(\" \", \"_\") if isinstance(item, str) else item for item in row1_cols]\n",
    "\n",
    "        df_data = df_raw.iloc[1:].copy()\n",
    "        df_data.columns = new_header\n",
    "        df_data.drop(1, axis=0, inplace=True)\n",
    "        df_data = df_data.loc[:, df_data.columns.notnull()].copy()\n",
    "        df_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_data.insert(0, \"date_time\", \"\")\n",
    "\n",
    "        df_data[\"date_time\"] = pd.to_datetime(\n",
    "            df_data[\"Year\"].astype(str)\n",
    "            + \"-\"\n",
    "            + df_data[\"Month\"].astype(str)\n",
    "            + \"-\"\n",
    "            + df_data[\"Day\"].astype(str)\n",
    "            + \" \"\n",
    "            + df_data[\"Hour\"].astype(str)\n",
    "            + \":\"\n",
    "            + df_data[\"Minute\"].astype(str)\n",
    "            + \":\"\n",
    "            + \"00\"\n",
    "        )\n",
    "\n",
    "        # df_data.drop([\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\"], axis=1, inplace=True)\n",
    "        df_data.drop([\"Minute\"], axis=1, inplace=True)\n",
    "        df_data.insert(1, \"zipcode\", zip_code)\n",
    "        df_data.insert(2, \"location_id\", df_meta[\"Location ID\"])\n",
    "\n",
    "        data_names = [\n",
    "            (df_data, \"nsrdb_\" + str(zip_code) + \"_\" + str(year) + \".csv\"),\n",
    "            (df_meta, \"nsrdb_meta_\" + str(zip_code) + \"_\" + str(year) + \".csv\"),\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            for item in data_names:\n",
    "                item[0].to_csv(\"~/_UMSI/697/data/nsrdb_raw/\" + item[1], index=True)\n",
    "                logger.info(f\"{item[1]} successfully written.\\n\")\n",
    "        except:\n",
    "            logger.error(\"Error writing .csv raw file(s)\")\n",
    "\n",
    "        try:\n",
    "            cursor.execute(queries.select_zip_year, {\"zipcode\": zip_code, \"year\": year})\n",
    "            count = cursor.fetchone()\n",
    "            print(count)\n",
    "\n",
    "            if (count[0] == \"8760\") or (count[0] == \"8784\"):\n",
    "                logger.warning(f\"data for {year}, {zip_code} already present\\n\")\n",
    "            else:\n",
    "                df_data.to_sql(\"nsrdb\", conn, if_exists=\"append\", index=False, method=\"multi\")\n",
    "                logger.info(f\"data for {year}, {zip_code} written to {db_file}:{db_table1}\\n\")\n",
    "        except:\n",
    "            logger.error(\"Error writing to nsrdb\\n\")\n",
    "\n",
    "        llltze_params = {\n",
    "            \"loc_id\": df_meta[\"Location ID\"],\n",
    "            \"lat\": df_meta[\"Latitude\"],\n",
    "            \"lon\": df_meta[\"Longitude\"],\n",
    "            \"elev\": df_meta[\"Elevation\"],\n",
    "            \"tz\": df_meta[\"Time Zone\"],\n",
    "            \"zipcode\": zip_code,\n",
    "        }\n",
    "        logger.info(f\"{llltze_params}\\n\")\n",
    "\n",
    "        cursor.execute(queries.update_gzc_llltze, llltze_params)\n",
    "        conn.commit()\n",
    "\n",
    "        cursor.execute(queries.select_zipcode, {\"zipcode\": zip_code})\n",
    "        logger.info(f\"gzc: {cursor.fetchall()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46949088-cc81-4360-bddc-d82ac89b3c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meta.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95de0d-64be-4927-95ff-fb29051f101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    \"Source\",\n",
    "    \"Location ID\",\n",
    "    \"City\",\n",
    "    \"State\",\n",
    "    \"Country\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Time Zone\",\n",
    "    \"Elevation\",\n",
    "    \"Local Time Zone\",\n",
    "    \"Clearsky DHI Units\",\n",
    "    \"Clearsky DNI Units\",\n",
    "    \"Clearsky GHI Units\",\n",
    "    \"Dew Point Units\",\n",
    "    \"DHI Units\",\n",
    "    \"DNI Units\",\n",
    "    \"GHI Units\",\n",
    "    \"Solar Zenith Angle Units\",\n",
    "    \"Temperature Units\",\n",
    "    \"Pressure Units\",\n",
    "    \"Relative Humidity Units\",\n",
    "    \"Precipitable Water Units\",\n",
    "    \"Wind Direction Units\",\n",
    "    \"Wind Speed\",\n",
    "    \"Cloud Type -15\",\n",
    "    \"Cloud Type 0\",\n",
    "    \"Cloud Type 1\",\n",
    "    \"Cloud Type 2\",\n",
    "    \"Cloud Type 3\",\n",
    "    \"Cloud Type 4\",\n",
    "    \"Cloud Type 5\",\n",
    "    \"Cloud Type 6\",\n",
    "    \"Cloud Type 7\",\n",
    "    \"Cloud Type 8\",\n",
    "    \"Cloud Type 9\",\n",
    "    \"Cloud Type 10\",\n",
    "    \"Cloud Type 11\",\n",
    "    \"Cloud Type 12\",\n",
    "    \"Fill Flag 0\",\n",
    "    \"Fill Flag 1\",\n",
    "    \"Fill Flag 2\",\n",
    "    \"Fill Flag 3\",\n",
    "    \"Fill Flag 4\",\n",
    "    \"Fill Flag 5\",\n",
    "    \"Surface Albedo Units\",\n",
    "    \"Version\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49b760-a8a9-4d9e-a8ca-0a851ed0aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"NSRDB\",\n",
    "    \"720555\",\n",
    "    \"-\",\n",
    "    \"-\",\n",
    "    \"-\",\n",
    "    \"36.01\",\n",
    "    \"-95.98\",\n",
    "    \"-6\",\n",
    "    \"194\",\n",
    "    \"-6\",\n",
    "    \"w/m2\",\n",
    "    \"w/m2\",\n",
    "    \"w/m2\",\n",
    "    \"c\",\n",
    "    \"w/m2\",\n",
    "    \"w/m2\",\n",
    "    \"w/m2\",\n",
    "    \"Degree\",\n",
    "    \"c\",\n",
    "    \"mbar\",\n",
    "    \"%\",\n",
    "    \"cm\",\n",
    "    \"Degrees\",\n",
    "    \"m/s\",\n",
    "    nan,\n",
    "    \"Clear\",\n",
    "    \"Probably Clear\",\n",
    "    \"Fog\",\n",
    "    \"Water\",\n",
    "    \"Super-Cooled Water\",\n",
    "    \"Mixed\",\n",
    "    \"Opaque Ice\",\n",
    "    \"Cirrus\",\n",
    "    \"Overlapping\",\n",
    "    \"Overshooting\",\n",
    "    \"Unknown\",\n",
    "    \"Dust\",\n",
    "    \"Smoke\",\n",
    "    nan,\n",
    "    \"Missing Image\",\n",
    "    \"Low Irradiance\",\n",
    "    \"Exceeds Clearsky\",\n",
    "    \"Missing CLoud Properties\",\n",
    "    \"Rayleigh Violation\",\n",
    "    nan,\n",
    "    \"3.0.6\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f739ff-23fb-4b82-baaf-98e942341122",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c487d69-9a8f-46d9-894b-87fd0b6237ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
