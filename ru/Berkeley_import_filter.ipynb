{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "    \n",
    "with open(\"cfg.json\", \"r\") as jin:\n",
    "    cfg = json.loads(jin.read())\n",
    "\n",
    "# rewrite to ensure formatting\n",
    "with open(\"cfg.json\", \"w\") as jout:\n",
    "    json.dump(cfg, jout, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_anomalies(data):\n",
    "    #define a list to accumlate anomalies\n",
    "    anomalies = []\n",
    "    \n",
    "    # Set upper and lower limit to 3 standard deviation\n",
    "    random_data_std = np.std(data)\n",
    "    random_data_mean = np.mean(data)\n",
    "    anomaly_cut_off = random_data_std * 3\n",
    "    \n",
    "    lower_limit  = random_data_mean - anomaly_cut_off \n",
    "    upper_limit = random_data_mean + anomaly_cut_off\n",
    "    #print(lower_limit, upper_limit)\n",
    "    # Generate outliers\n",
    "    for outlier in data:\n",
    "        if outlier > upper_limit or outlier < lower_limit:\n",
    "            anomalies.append(outlier)\n",
    "    return anomalies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installation_data_res(files):\n",
    "    for i, file in enumerate(files):\n",
    "        bk1 = pd.read_csv(file,encoding= 'unicode_escape', low_memory = False)\n",
    "        if i == 0:\n",
    "            bk = bk1.copy()\n",
    "        else:\n",
    "            bk = pd.concat([bk,bk1])\n",
    "    \n",
    "    bk = bk.replace({-9999:np.NaN}).replace({\"-9999\":np.NaN})\n",
    "\n",
    "\n",
    "    \n",
    "    bk_P = bk[(bk['customer_segment'] == 'RES') & (bk.zip_code != 'redacted')]\n",
    "    bk_P = bk_P[cfg[\"filter_cols\"]]\n",
    "\n",
    "    bk_P['battery_rated_capacity_kWh'] = bk_P['battery_rated_capacity_kWh'].fillna(0)\n",
    "    bk_P['installation_date'] = pd.to_datetime(bk_P['installation_date'])\n",
    "    bk_P = bk_P.dropna(subset=['zip_code'])\n",
    "    bk_P['zip_code'] = bk_P['zip_code'].apply(lambda a: str(a).split('-')[0].zfill(5))\n",
    "    \n",
    "    bk_P['install_month'] = bk_P.installation_date.dt.strftime('%Y-%m')\n",
    "    bk_P['install_month'] = pd.to_datetime(bk_P['install_month']) + MonthEnd(1)\n",
    "    \n",
    "    bk_P_3 = bk_P[bk_P.system_size_DC <= 25]\n",
    "    \n",
    "    bk_P_rt = bk_P_3[(bk_P_3.ground_mounted != 1) & (bk_P_3.third_party_owned != 1) & (bk_P_3.battery_rated_capacity_kWh == 0)]\n",
    "    bk_P_rt['cost_per_kW'] = bk_P_rt.total_installed_price/bk_P_rt.system_size_DC\n",
    "    costs_df = bk_P_rt.groupby('install_month').cost_per_kW.mean().reset_index().dropna()\n",
    "    \n",
    "    bk_P_rt['days_from_first'] = int(str(bk_P_rt.installation_date - bk_P_rt.installation_date.min()).split()[0])\n",
    "    bk_P_rt_cost = bk_P_rt.dropna(subset = ['cost_per_kW'])\n",
    "    bk_P_rt_cost['PCA_cost'] = PCA(n_components = 1).fit_transform(bk_P_rt_cost[['days_from_first','cost_per_kW']])\n",
    "    outliers = find_anomalies(bk_P_rt_cost.PCA_cost)\n",
    "    bk_P_rt_cost = bk_P_rt_cost[~bk_P_rt_cost.PCA_cost.isin(outliers)]\n",
    "    costs_df2 = bk_P_rt_cost.groupby('install_month').cost_per_kW.mean().reset_index().dropna()\n",
    "    \n",
    "    bk_P_rt_cost['rebate_per_kW'] = bk_P_rt_cost.rebate_or_grant/bk_P_rt_cost.system_size_DC\n",
    "    rebate_df = bk_P_rt_cost.groupby('install_month').rebate_or_grant.mean().reset_index().dropna()\n",
    "    \n",
    "    total_RES_size_25 = bk_P_rt.groupby('zip_code').system_size_DC.count().reset_index().rename(columns = {'system_size_DC':'number_installs'})\n",
    "    \n",
    "    sub_25_map = dict(zip(total_RES_size_25.zip_code, total_RES_size_25.number_installs))\n",
    "    \n",
    "    return sub_25_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-4d8eac82fc27>:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bk_P_rt['cost_per_kW'] = bk_P_rt.total_installed_price/bk_P_rt.system_size_DC\n",
      "<ipython-input-15-4d8eac82fc27>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bk_P_rt['days_from_first'] = int(str(bk_P_rt.installation_date - bk_P_rt.installation_date.min()).split()[0])\n",
      "<ipython-input-15-4d8eac82fc27>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bk_P_rt_cost['PCA_cost'] = PCA(n_components = 1).fit_transform(bk_P_rt_cost[['days_from_first','cost_per_kW']])\n"
     ]
    }
   ],
   "source": [
    "files = [cfg[\"data_dir\"] + cfg[\"berkeley_1\"],\n",
    "         cfg[\"data_dir\"] + cfg[\"berkeley_2\"]]\n",
    "\n",
    "sub_25 = installation_data_res(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sub_25.p', 'wb') as fp:\n",
    "    pickle.dump(sub_25, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
