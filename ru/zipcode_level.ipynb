{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "#import query\n",
    "import logzero\n",
    "import requests\n",
    "#import secret\n",
    "import numpy as np\n",
    "from logzero import logger\n",
    "from requests import get\n",
    "import calendar\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from itertools import cycle, islice\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "#import query\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.metrics import accuracy_score, silhouette_samples, silhouette_score\n",
    "from sklearn.metrics.cluster import completeness_score, homogeneity_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "from pandas.tseries.offsets import MonthEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering full list of US zip codes\n",
    "\n",
    "all_zips = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('../data/uszips.txt', 'r') as filehandle:\n",
    "    filecontents = filehandle.readlines()\n",
    "\n",
    "    for line in filecontents:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        current_place = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        all_zips.append(current_place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gathering zip codes which have necessary data for installation\n",
    "\n",
    "data_zips = []\n",
    "\n",
    "# open file and read the content in a list\n",
    "with open('../data/datazips.txt', 'r') as filehandle:\n",
    "    filecontents = filehandle.readlines()\n",
    "\n",
    "    for line in filecontents:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        current_place = line[:-1]\n",
    "\n",
    "        # add item to the list\n",
    "        data_zips.append(current_place)\n",
    "        \n",
    "data_zips = sorted(data_zips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4470492396813903"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_zips = len(data_zips)/len(all_zips)\n",
    "percent_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipdata(zipcode):\n",
    "    code = search.by_zipcode(zipcode)\n",
    "    code = code.to_dict()\n",
    "    #print(code)\n",
    "    income = code[\"median_household_income\"]\n",
    "    value = code[\"median_home_value\"]\n",
    "    density = code[\"population_density\"]\n",
    "    land_area = code[\"land_area_in_sqmi\"]\n",
    "    houses = code[\"housing_units\"]\n",
    "    state = code[\"state\"]\n",
    "    return income, value, density, houses, land_area, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_df = pd.DataFrame({'zipcode':data_zips})\n",
    "zip_df['income'],zip_df['value'],zip_df['density'],zip_df['houses'],zip_df['land'], zip_df['state'] = zip(*zip_df[\"zipcode\"].map(zipdata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ParseException: Unknown type: '../PLOTLY_ZIPS.GEOJSON'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't parse ../plotly_zips.geojson as a geojson Feature object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mread_features\u001b[0;34m(obj, layer)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureCollection'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fba5495af96e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrasterstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzonal_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzonal_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../plotly_zips.geojson\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/nsrdb_full_disc_2019_dni_scaled.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mirradiance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterstats/main.py\u001b[0m in \u001b[0;36mzonal_stats\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0monly\u001b[0m \u001b[0mdifference\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzonal_stats\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     return a list rather than a generator.\"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_zonal_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterstats/main.py\u001b[0m in \u001b[0;36mgen_zonal_stats\u001b[0;34m(vectors, raster, layer, band, nodata, affine, stats, all_touched, categorical, category_map, add_stats, zone_func, raster_out, prefix, geojson_out, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mRaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mfeatures_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mgeom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mread_features\u001b[0;34m(obj, layer)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;31m# Single feature-like string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mfeatures_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparse_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'type'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'FeatureCollection'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/rasterstats/io.py\u001b[0m in \u001b[0;36mparse_feature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't parse %s as a geojson Feature object\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't parse ../plotly_zips.geojson as a geojson Feature object"
     ]
    }
   ],
   "source": [
    "from rasterstats import zonal_stats\n",
    "stats = zonal_stats(\"../plotly_zips.geojson\", \"../data/nsrdb_full_disc_2019_dni_scaled.tif\")\n",
    "irradiance = [f['mean'] for f in stats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../plotly_zips.geojson\") as f:\n",
    "    zips = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_ids = [i['id'] for i in zips['features']]\n",
    "\n",
    "irr_map = dict(zip(zip_ids,irradiance))\n",
    "\n",
    "zip_df['irradiance'] = zip_df.zipcode.map(irr_map)\n",
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_excel(\"../data/avgprice_annual.xlsx\", header=1)\n",
    "\n",
    "prices_res_2019 = prices[(prices[\"Industry Sector Category\"] == \"Total Electric Industry\") & (prices.Year == 2019)][['State','Residential']]\n",
    "price_map = dict(zip(prices_res_2019.State, prices_res_2019.Residential))\n",
    "\n",
    "zip_df['e_price'] = zip_df.state.map(price_map)\n",
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricians = pd.read_csv(\"../data/PolicyMap Data 2021-07-09 0319UTC.csv\")\n",
    "electricians = electricians.rename(columns = {\"Average annual wage in the specialty trade contractors industry \":\"Avg_wage\"})\n",
    "electricians_2 = electricians.copy()\n",
    "electricians = electricians[['FIPS Code','Avg_wage']].dropna().astype(int)\n",
    "electricians['FIPS Code'] = electricians['FIPS Code'].astype(str).apply(lambda n: n.zfill(5))\n",
    "electricians.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_county = pd.read_excel(\"../data/ZIP_COUNTY_032021.xlsx\", header=0)\n",
    "zip_county = zip_county[[\"ZIP\",\"COUNTY\"]].astype(str)\n",
    "\n",
    "zip_county['ZIP'] = zip_county.ZIP.apply(lambda n: n.zfill(5))\n",
    "zip_county['COUNTY'] = zip_county.COUNTY.apply(lambda n: n.zfill(5))\n",
    "\n",
    "z_c = dict(zip(zip_county.ZIP,zip_county.COUNTY))\n",
    "c_w = dict(zip(electricians['FIPS Code'],electricians.Avg_wage))\n",
    "\n",
    "zip_df['county'] = zip_df.zipcode.map(z_c)\n",
    "zip_df['avg_contractor_wage'] = zip_df.county.map(c_w)\n",
    "zip_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cluster_df = zip_df[['zipcode','income','value','density',\n",
    "                         'houses','land','irradiance',\n",
    "                         'e_price','avg_contractor_wage']].rename(\n",
    "    columns = {'income':'med_income','value':'med_home_value',\n",
    "               'density':'pop_density','houses':'home_count',\n",
    "               'land':'land_area','irradiance': 'NREL_PSM_2019', \n",
    "               'e_price': 'cost_electricity'})\n",
    "zip_cluster_df[['med_income', 'med_home_value', \n",
    "                'pop_density', 'home_count',\n",
    "                'land_area', 'NREL_PSM_2019', \n",
    "                'cost_electricity','avg_contractor_wage']] = zip_cluster_df[['med_income', 'med_home_value', \n",
    "                                                                             'pop_density', 'home_count',\n",
    "                                                                             'land_area', 'NREL_PSM_2019', \n",
    "                                                                             'cost_electricity','avg_contractor_wage']].astype(float)\n",
    "zip_cluster_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cluster_df_full = zip_cluster_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.choropleth_mapbox(zip_cluster_df_full, geojson=zips, locations='zipcode', color='NREL_PSM_2019',\n",
    "#                            color_continuous_scale=\"Viridis\",\n",
    "#                            mapbox_style=\"carto-positron\",\n",
    "#                            zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "#                            opacity=0.5,\n",
    "#                            labels={'NREL_PSM_2019':'PSM'}\n",
    "#                           )\n",
    "# fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cluster_df_full['housing_density'] = zip_cluster_df_full.home_count.values/zip_cluster_df_full.land_area.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(data=bk_P[['system_size_DC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(data=bk_P_2[['system_size_DC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.violinplot(data=bk_P_3[['system_size_DC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data=costs_df, x=\"install_month\", y=\"cost_per_kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data=costs_df2, x=\"install_month\", y=\"cost_per_kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lineplot(data=rebate_df, x=\"install_month\", y=\"rebate_or_grant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sub_25.p', 'rb') as fp:\n",
    "    sub_25_map = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cluster_df_full['install_count'] = zip_cluster_df_full.zipcode.map(sub_25_map)\n",
    "zip_cluster_df_full['percent_homes'] = zip_cluster_df_full.install_count.values/zip_cluster_df_full.home_count.values\n",
    "zip_cluster_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "\n",
    "# fig = px.choropleth_mapbox(zip_cluster_df_full, geojson=zips, locations='zipcode', color='percent_homes',\n",
    "#                            color_continuous_scale=\"Viridis\",\n",
    "#                            mapbox_style=\"carto-positron\",\n",
    "#                            zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "#                            opacity=0.5,\n",
    "#                            labels={'system_size_DC':'kW'}\n",
    "#                           )\n",
    "# fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_pair = zip_cluster_df_full[['med_income', \n",
    "                               'med_home_value', \n",
    "                               'pop_density', \n",
    "                               'NREL_PSM_2019', \n",
    "                               'cost_electricity', \n",
    "                               'avg_contractor_wage',\n",
    "                               'percent_homes']].dropna()\n",
    "\n",
    "#zc_pair['cap_per_home'] = pd.cut(zc_pair.cap_per_home, bins = 5)\n",
    "#zc_pair.head()\n",
    "sns.pairplot(data = zc_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = zc_pair.drop(columns = 'percent_homes')\n",
    "y = zc_pair.percent_homes\n",
    "\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_pair['prediction'] = model.predict(X)\n",
    "zc_pair['performance_vs_expectation'] = (zc_pair.percent_homes - zc_pair.prediction) / zc_pair.prediction\n",
    "zc_pair['zipcode'] = zip_cluster_df_full.zipcode\n",
    "\n",
    "zc_pair = zc_pair[~zc_pair['performance_vs_expectation'].isin(find_anomalies(zc_pair['performance_vs_expectation']))]\n",
    "zc_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth_mapbox(zc_pair, geojson=zips, locations='zipcode', color='performance_vs_expectation',\n",
    "                           color_continuous_scale=\"Viridis\",\n",
    "                           mapbox_style=\"carto-positron\",\n",
    "                           zoom=3, center = {\"lat\": 37.0902, \"lon\": -95.7129},\n",
    "                           opacity=0.5,\n",
    "                           labels={'system_size_DC':'kW'}\n",
    "                          )\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zc_pair.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/earliest_dates.p', 'rb') as fp:\n",
    "    earliest_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, axes = plt.subplots(25,figsize = (12, 120))\n",
    "min_yr = pd.to_datetime('1998-04-30 00:00:00').year\n",
    "min_mo = pd.to_datetime('1998-04-30 00:00:00').month\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, key in enumerate(earliest_dict.keys()):\n",
    "    eval_df =  bk_P_rt[bk_P_rt.zip_code.isin(earliest_dict[key].keys())]\n",
    "    eval_df['p_mo'] = eval_df.zip_code.map(earliest_dict[key])\n",
    "    \n",
    "    eval_df['num_months'] = eval_df.install_month.apply(\n",
    "        lambda d: (d.year - min_yr) * 12 + (d.month - min_mo)\n",
    "    )\n",
    "    \n",
    "    eval_df['program_months'] = eval_df.num_months - eval_df.p_mo\n",
    "    \n",
    "    eval_df['total_cost'] = eval_df.total_installed_price - eval_df.rebate_or_grant\n",
    "    #eval_df['prog_date'] = pd.to_datetime(eval_df.zip_code.map(program_dict[key]))\n",
    "    #eval_df['num_months'] = (eval_df.install_month.dt.year - eval_df['prog_date'].dt.year) * 12 + (eval_df.install_month.dt.month - eval_df['prog_date'].dt.month)\n",
    "    \n",
    "    plotter = eval_df.groupby(['p_mo','program_months']).total_cost.count().reset_index()\n",
    "    #display(plotter.sort_values(by = 'num_months').head(20))\n",
    "    #plotter['prog_date'] = plotter['prog_date'].apply(lambda c: str(c))\n",
    "    maxes = plotter.groupby(['p_mo']).total_cost.max().reset_index()\n",
    "    max_dict = dict(zip(maxes.p_mo,maxes.total_cost))\n",
    "    plotter['max_val'] = plotter.p_mo.map(max_dict)\n",
    "    plotter['percent_max'] = plotter.total_cost / plotter.max_val\n",
    "    plotter_2 = plotter.groupby('program_months').percent_max.mean().reset_index()\n",
    "    sns.lineplot(ax=axes[i], data=plotter_2, x='program_months', y='percent_max')  \n",
    "    axes[i].set_title(\"program_id_{}\".format(str(key)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_cluster_df_full['install_level'] = pd.qcut(zip_cluster_df_full.percent_homes, 7,\n",
    "                                              labels=[0,1,2,3,4,5,6]) #\"low\", \"med-low\", \"med\", \"med-high\",\"high\"\n",
    "zip_cluster_df_full = zip_cluster_df_full.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_pipe = Pipeline(\n",
    "#     [\n",
    "        \n",
    "#         (\"standard\",StandardScaler()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# df_raw = zip_cluster_df_full.copy()[['housing_density','med_income','NREL_PSM_2019', 'cost_electricity']]\n",
    "# df_transformed = scale_pipe.fit_transform(df_raw)\n",
    "\n",
    "# h_scores = {}\n",
    "# c_scores = {}\n",
    "\n",
    "\n",
    "\n",
    "# y_WS = zip_cluster_df_full.install_level\n",
    "# # reduced hyperparameters for runtime savings - derived from wider range\n",
    "# for i in np.linspace(.2,.5,16):\n",
    "#     for j in np.linspace(5,50,10):\n",
    "#         try:\n",
    "#             dbscan = DBSCAN(eps = i, min_samples = j)\n",
    "#             cls = dbscan.fit_predict(df_transformed)\n",
    "#             hs = homogeneity_score(cls, y_WS)\n",
    "#             cs = completeness_score(cls, y_WS)\n",
    "#             if len(np.unique(cls)) > 1:\n",
    "#                 h_scores[(i,j)] = hs\n",
    "#                 c_scores[(i,j)] = cs\n",
    "#             else:\n",
    "#                 h_scores[(i,j)] = 0\n",
    "#                 c_scores[(i,j)] = 0\n",
    "#         except:\n",
    "#             h_scores[(i,j)] = 0\n",
    "#             c_scores[(i,j)] = 0\n",
    "# sdh = sorted(h_scores.items(), key=lambda item: item[1], reverse = True)\n",
    "# sdc = sorted(c_scores.items(), key=lambda item: item[1], reverse = True)\n",
    "    \n",
    "    \n",
    "# sdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = zip_cluster_df_full.copy()[['housing_density','med_income','NREL_PSM_2019', 'cost_electricity']]\n",
    "# df_transformed = scale_pipe.fit_transform(df_raw)\n",
    "\n",
    "\n",
    "# i_c = zip_cluster_df_full.install_level\n",
    "\n",
    "# agg = DBSCAN(eps = .22, min_samples = 5) #AgglomerativeClustering(n_clusters = 11)\n",
    "# cls_a2 = agg.fit_predict(df_transformed)\n",
    "\n",
    "# pca_a = df_transformed.copy()\n",
    "# tsne_a = df_transformed.copy()\n",
    "\n",
    "# X_pca_a = PCA(n_components = 2, random_state=42).fit_transform(pca_a)\n",
    "# X_tsne_a = TSNE(n_components = 2, random_state = 42).fit_transform(tsne_a)\n",
    "\n",
    "# plt.clf()\n",
    "# fig, axes = plt.subplots(4, figsize=(12,12))\n",
    "\n",
    "# axes[0].scatter(X_pca_a[:, 0], X_pca_a[:, 1], s=10, c=cls_a2)\n",
    "# axes[1].scatter(X_tsne_a[:, 0], X_tsne_a[:, 1], s=10, c=cls_a2)\n",
    "# axes[2].scatter(X_pca_a[:, 0], X_pca_a[:, 1], s=10, c=i_c)\n",
    "# axes[3].scatter(X_tsne_a[:, 0], X_tsne_a[:, 1], s=10, c=i_c)\n",
    "\n",
    "\n",
    "\n",
    "# axes[0].set_title(\"PCA_Agglomerative\")\n",
    "# axes[1].set_title(\"tsne_Agglomerative\")\n",
    "# axes[0].set_title(\"PCA_lvl\")\n",
    "# axes[1].set_title(\"tsne_lvl\")\n",
    "        \n",
    "# cs = completeness_score(cls_a2, i_c)\n",
    "# print(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = ['CA','OR','WA','AZ','NM','TX','FL','NY','MA', 'WI','PA']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
