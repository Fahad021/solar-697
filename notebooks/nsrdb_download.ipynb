{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e34ae454-1939-4950-afe3-b52d6ddea083",
   "metadata": {},
   "source": [
    "### NSRDB Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f75a151-807b-4ccc-a7f1-9f735317e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import site\n",
    "import sqlite3\n",
    "import sys\n",
    "from time import sleep\n",
    "\n",
    "import logzero\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from logzero import logger\n",
    "from tqdm import tqdm\n",
    "from yaml import dump, load, safe_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ebae6f-c7d2-4aab-9b92-2ba92352e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../source\")\n",
    "import queries\n",
    "from secret import nrel_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df7ea666-17e0-4f2e-8c27-85f599650937",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = \"logs/\"\n",
    "log_file = \"nsrdb_download.log\"\n",
    "\n",
    "logzero.logfile(log_path + log_file, maxBytes=1e5, backupCount=5, disableStderrLogger=True)\n",
    "logger.info(f\"{log_path}, {log_file}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54798d9e-ad6f-48a0-ae8f-fb98a9ecd9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = None\n",
    "try:\n",
    "    with open(\"../source/config.yml\", \"r\") as config_in:\n",
    "        configs = load(config_in, Loader=yaml.SafeLoader)\n",
    "        logger.info(f\"{configs}\\n\")\n",
    "except:\n",
    "    logger.error(f\"config file open failure.\")\n",
    "    exit(1)\n",
    "\n",
    "cfg_vars = configs[\"url_variables\"]\n",
    "logger.info(f\"variables: {cfg_vars}\\n\")\n",
    "\n",
    "years = configs[\"request_years\"]\n",
    "logger.info(f\"years: {years}\\n\")\n",
    "\n",
    "db_path = configs[\"file_paths\"][\"downloads_db_path\"]\n",
    "data_path = configs[\"file_paths\"][\"downloads_path_zips\"]\n",
    "raw_path = configs[\"file_paths\"][\"downloads_path_raw\"]\n",
    "\n",
    "city = configs[\"location_info\"][\"city\"]\n",
    "state = configs[\"location_info\"][\"state\"]\n",
    "db_file = city + \"_\" + state + \".db\"\n",
    "\n",
    "db_table1 = configs[\"table_names\"][\"db_table1\"]\n",
    "db_table2 = configs[\"table_names\"][\"db_table2\"]\n",
    "\n",
    "db_file2 = configs[\"file_names\"][\"db_file_gzc\"]\n",
    "\n",
    "logger.info(f\"{db_path}, {db_file}\")\n",
    "\n",
    "nrows = configs[\"num_rows\"][0]\n",
    "zip_import = configs[\"zip_import\"][False]\n",
    "\n",
    "logger.info(f\"number of rows: {nrows}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ccd876-3e19-48d8-87cf-9f37aff95197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../downloads/db/ for_test.db geo_zipcodes.db\n",
      "../downloads/us_census/zipcodes_for_test.yml\n"
     ]
    }
   ],
   "source": [
    "print(db_path, db_file, db_file2)\n",
    "print(data_path + \" zipcodes_\" + city + \"_\" + state + \".yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a9a7d4-d2c7-4c33-9a79-1e6ab72a8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(data_path + \"zipcodes_\" + city + \"_\" + state + \".yml\", \"r\") as locs_in:\n",
    "        locations = load(locs_in, Loader=yaml.SafeLoader)\n",
    "        logger.info(locations)\n",
    "except:\n",
    "    logger.error(f\"location file open failure.\")\n",
    "    exit(1)\n",
    "\n",
    "zip_codes = locations[\"zipcodes\"]\n",
    "\n",
    "logger.info(f\"zip codes: {zip_codes}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43d91261-7000-4778-bd6e-41cfe03948f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish db connection and cursor\n",
    "conn = sqlite3.connect(db_path + db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(queries.create_table_nsrdb)\n",
    "conn.commit()\n",
    "cursor.execute(queries.create_table_geo_zipcodes)\n",
    "conn.commit()\n",
    "\n",
    "conn2 = sqlite3.connect(db_path + db_file2)\n",
    "cursor2 = conn2.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca3a0fde-af4f-4384-beea-55d7b79c8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\"path\": db_path, \"db_file2\": db_file2}\n",
    "# need to test for existance of records in the db\n",
    "# and skip the import if so\n",
    "if zip_import:\n",
    "    cursor.execute(\"\"\"ATTACH DATABASE '../data/db/geo_zipcodes.db' AS gzc_db;\"\"\")\n",
    "    cursor.execute(\"\"\"INSERT INTO 'geo_zipcodes' SELECT * FROM gzc_db.geo_zipcodes;\"\"\")\n",
    "    conn.commit()\n",
    "    cursor.execute(\"DETACH gzc_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d88db-749d-4a53-9bb4-8fe3cd0de857",
   "metadata": {},
   "source": [
    "### Download link information\n",
    "https://developer.nrel.gov/docs/solar/nsrdb/psm3-download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073ff8a-44f7-433b-bf35-48cd1c645358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for zip_code in tqdm(zip_codes.keys()):\n",
    "        req_str = (\n",
    "            f\"https://developer.nrel.gov/api/solar/nsrdb_psm3_download.csv?\"\n",
    "            + f'wkt=POINT({zip_codes[zip_code][\"lon\"]}%20{zip_codes[zip_code][\"lat\"]})'\n",
    "            + f\"&names={year}\"\n",
    "            + f'&leap_day={cfg_vars[\"leap_year\"]}'\n",
    "            + f'&interval={cfg_vars[\"interval\"]}'\n",
    "            + f'&utc={cfg_vars[\"utc\"]}'\n",
    "            + f'&full_name={cfg_vars[\"name\"]}'\n",
    "            + f'&email={cfg_vars[\"email\"]}'\n",
    "            + f'&affiliation={cfg_vars[\"affiliation\"]}'\n",
    "            + f'&mailing_list={cfg_vars[\"mailing_list\"]}'\n",
    "            + f'&reason={cfg_vars[\"use\"]}'\n",
    "            + f\"&api_key={nrel_key}\"\n",
    "            + f'&attributes={cfg_vars[\"attrs\"]}'\n",
    "        )\n",
    "\n",
    "        logger.info(f\"{req_str}\\n\")\n",
    "\n",
    "        # sleep so we don't overrun the rate NREL limit\n",
    "        sleep(2)\n",
    "        try:\n",
    "            df_raw = pd.read_csv(req_str, nrows=nrows)\n",
    "            logger.info(\"reg_str successful.\")\n",
    "        except:\n",
    "            logger.error(f\"Error requesting\\n{req_str}\\n\")\n",
    "\n",
    "        # query and extract the first 2 lines to get metadata:\n",
    "        df_meta = df_raw.iloc[0].copy()\n",
    "        # display(df_meta)\n",
    "\n",
    "        row1_cols = df_raw.iloc[1]\n",
    "        new_header = [item.replace(\" \", \"_\") if isinstance(item, str) else item for item in row1_cols]\n",
    "\n",
    "        df_data = df_raw.iloc[1:].copy()\n",
    "        df_data.columns = new_header\n",
    "        df_data.drop(1, axis=0, inplace=True)\n",
    "        df_data = df_data.loc[:, df_data.columns.notnull()].copy()\n",
    "        df_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        df_data.insert(0, \"date_time\", \"\")\n",
    "\n",
    "        df_data[\"date_time\"] = pd.to_datetime(\n",
    "            df_data[\"Year\"].astype(str)\n",
    "            + \"-\"\n",
    "            + df_data[\"Month\"].astype(str)\n",
    "            + \"-\"\n",
    "            + df_data[\"Day\"].astype(str)\n",
    "            + \" \"\n",
    "            + df_data[\"Hour\"].astype(str)\n",
    "            + \":\"\n",
    "            + df_data[\"Minute\"].astype(str)\n",
    "            + \":\"\n",
    "            + \"00\"\n",
    "        )\n",
    "\n",
    "        # df_data.drop([\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\"], axis=1, inplace=True)\n",
    "        df_data.drop([\"Minute\"], axis=1, inplace=True)\n",
    "        df_data.insert(1, \"zipcode\", zip_code)\n",
    "        df_data.insert(2, \"location_id\", df_meta[\"Location ID\"])\n",
    "\n",
    "        data_names = [\n",
    "            (df_data, \"nsrdb_\" + str(zip_code) + \"_\" + str(year) + \".csv\"),\n",
    "            (df_meta, \"nsrdb_meta_\" + str(zip_code) + \"_\" + str(year) + \".csv\"),\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            for item in data_names:\n",
    "                item[0].to_csv(raw_path + item[1], index=True)\n",
    "                logger.info(f\"{item[1]} successfully written.\\n\")\n",
    "        except:\n",
    "            logger.error(\"Error writing .csv raw file(s)\")\n",
    "\n",
    "        try:\n",
    "            cursor.execute(queries.select_zip_year, {\"zipcode\": zip_code, \"year\": year})\n",
    "            count = cursor.fetchone()\n",
    "            # print(count)\n",
    "\n",
    "            if (count[0] == \"8760\") or (count[0] == \"8784\"):\n",
    "                logger.warning(f\"data for {year}, {zip_code} already present\\n\")\n",
    "            else:\n",
    "                df_data.to_sql(\"nsrdb\", conn, if_exists=\"append\", index=False, method=\"multi\")\n",
    "                logger.info(f\"data for {year}, {zip_code} written to {db_file}:{db_table1}\\n\")\n",
    "        except:\n",
    "            logger.error(\"Error writing to nsrdb\\n\")\n",
    "\n",
    "        llltze_params = {\n",
    "            \"loc_id\": df_meta[\"Location ID\"],\n",
    "            \"lat\": df_meta[\"Latitude\"],\n",
    "            \"lon\": df_meta[\"Longitude\"],\n",
    "            \"elev\": df_meta[\"Elevation\"],\n",
    "            \"tz\": df_meta[\"Time Zone\"],\n",
    "            \"zipcode\": zip_code,\n",
    "        }\n",
    "        logger.info(f\"{llltze_params}\\n\")\n",
    "\n",
    "        cursor.execute(queries.update_gzc_llltze, llltze_params)\n",
    "        conn.commit()\n",
    "\n",
    "        cursor2.execute(queries.update_gzc_llltze, llltze_params)\n",
    "        conn2.commit()\n",
    "\n",
    "        cursor.execute(queries.select_zipcode, {\"zipcode\": zip_code})\n",
    "        logger.info(f\"gzc: {cursor.fetchall()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f739ff-23fb-4b82-baaf-98e942341122",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c487d69-9a8f-46d9-894b-87fd0b6237ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
